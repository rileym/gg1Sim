# gg1Sim

  This is a [G/G/1 queue](http://en.wikipedia.org/wiki/G/G/1_queue) simulation I wrote for a simulation class. The purpose of the exercise is to demonstrate the potential sensitivity of certain performance metrics to the choice of "input distribution” in a given simulation. In this case the metric is mean queue length, `L`, and the input distribution is the distribution of inter-arrival times. I had learned basic python the week before this assignment and so took the exercise as an opportunity to further familiarize myself with python and object oriented pyhton. Note too that we were not allowed to use any high level packages or routines in this assignment, e.g., no numpy, no scipy, and had to generate our own random variables.

### Specifics of the queue simulation:

  We are trying to estimate `L`, the average queue legnth for five different G/G/1 queues. For all five queues the service times are generated by the sum of two independent uniform random variables (this distribution looks like a triangle). The inter-arrival times for the queues are as follows: exponential, weibul (2x: once for each of two different parameter setting), and auto-correlated normal random variables (2x: one with positive and one with negative correlation). If I remember correctly, the parameters are calibrated so that all five inter-arrival distributions have the same mean. Even so, — and this is the moral of the exercise to some extent —, the differences in the shape of these distributions or their non-independence leads to very different values of `L`, or in other words, the performance metric is sensitive to the choice of input distribution.

  The formal model behind this simulation is a "generalized semi-markov process" (GSMP) which is a stochastic process description of a discrete event system.



